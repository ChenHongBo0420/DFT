{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yJtObk4L0mGk",
        "outputId": "5ba4118d-dcbc-4074-b12c-cd74260578d4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m47.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m26.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m173.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m181.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m42.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m37.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m73.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m76.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m65.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m71.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m140.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10/10\u001b[0m [nvidia-cusolver-cu12]\n",
            "\u001b[1A\u001b[2K  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.1/5.1 MB\u001b[0m \u001b[31m113.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m739.1/739.1 kB\u001b[0m \u001b[31m36.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m809.0/809.0 kB\u001b[0m \u001b[31m36.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[33m  DEPRECATION: Building 'bibtexparser' using the legacy setup.py bdist_wheel mechanism, which will be removed in a future version. pip 25.3 will enforce this behaviour change. A possible replacement is to use the standardized build interface by setting the `--use-pep517` option, (possibly combined with `--no-build-isolation`), or adding a `pyproject.toml` file to the source tree of 'bibtexparser'. Discussion can be found at https://github.com/pypa/pip/issues/6334\u001b[0m\u001b[33m\n",
            "\u001b[0m  Building wheel for bibtexparser (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8/8\u001b[0m [pymatgen]\n",
            "\u001b[1A\u001b[2KSamples for CHG:     Train=13  Val=2  Test=4\n",
            "Samples for Energy:  Train=13  Val=2  Test=4\n",
            "Samples for DOS:     Train=9  Val=1  Test=2\n"
          ]
        }
      ],
      "source": [
        "# ===============================================================\n",
        "# DFTpy:  Mount Drive / clone repo / build CSVs only\n",
        "# ===============================================================\n",
        "\n",
        "# ① Mount Drive -------------------------------------------------\n",
        "from google.colab import drive\n",
        "!rm -rf /content/drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# ② Install deps ------------------------------------------------\n",
        "!pip -q install --upgrade pip\n",
        "!pip -q install torch torchvision torchaudio\n",
        "!pip -q install numpy pandas pymatgen scikit-learn h5py tqdm joblib\n",
        "\n",
        "# ③ Clone fresh DFTpy ------------------------------------------- -------------------------------------------\n",
        "import os, random\n",
        "from pathlib import Path\n",
        "import pandas as pd\n",
        "\n",
        "# 切换到工作目录并克隆仓库（如已存在则跳过）\n",
        "os.chdir('/content')\n",
        "if not Path('DFT').exists():\n",
        "    !git clone -q https://github.com/ChenHongBo0420/DFT.git\n",
        "\n",
        "# ③ 收集所有样本目录 --------------------------------------------\n",
        "base = Path('/content/DFT/database')\n",
        "all_dirs    = set()\n",
        "energy_dirs = set()\n",
        "dos_dirs    = set()\n",
        "\n",
        "for pos in base.rglob('POSCAR'):\n",
        "    root = pos.parent.parent if pos.parent.name.upper() == 'POSCAR' else pos.parent\n",
        "    all_dirs.add(root.as_posix())\n",
        "    # 判断完整数据\n",
        "    if (root/'energy').is_file() and (root/'forces').is_file() and (root/'stress').is_file():\n",
        "        energy_dirs.add(root.as_posix())\n",
        "    if (root/'dos').is_file() and (root/'VB_CB').is_file():\n",
        "        dos_dirs.add(root.as_posix())\n",
        "\n",
        "# ④ 划分 Train/Val/Test ------------------------------------------\n",
        "\n",
        "def split(lst, ratio=0.7):\n",
        "    lst = list(lst)\n",
        "    random.shuffle(lst)\n",
        "    n = len(lst)\n",
        "    n_tr  = max(int(n * ratio), 1)\n",
        "    n_val = max(int(n * 0.15), 1)\n",
        "    if n_tr + n_val >= n:\n",
        "        n_tr = max(n - 2, 1)\n",
        "        n_val = 1\n",
        "    return lst[:n_tr], lst[n_tr:n_tr + n_val]\n",
        "\n",
        "tr_all, val_all = split(all_dirs)\n",
        "tr_en,  val_en  = split(energy_dirs) if energy_dirs else ([], [])\n",
        "tr_dos, val_dos = split(dos_dirs)    if dos_dirs    else ([], [])\n",
        "# 测试集为剩余所有样本\n",
        "test_all = sorted(all_dirs - set(tr_all) - set(val_all))\n",
        "\n",
        "# ⑤ 写 CSV 并打印样本数 ------------------------------------------\n",
        "csv_dir = Path('/content/drive/MyDrive/DFT_CSVs')\n",
        "csv_dir.mkdir(exist_ok=True)\n",
        "\n",
        "pd.DataFrame({'files':    tr_all}).to_csv(csv_dir/'Train_all.csv',   index=False)\n",
        "pd.DataFrame({'files':    val_all}).to_csv(csv_dir/'Val_all.csv',     index=False)\n",
        "pd.DataFrame({'files':    tr_en }).to_csv(csv_dir/'Train_energy.csv',index=False)\n",
        "pd.DataFrame({'files':    val_en }).to_csv(csv_dir/'Val_energy.csv',  index=False)\n",
        "pd.DataFrame({'files':    tr_dos}).to_csv(csv_dir/'Train_dos.csv',   index=False)\n",
        "pd.DataFrame({'files':    val_dos}).to_csv(csv_dir/'Val_dos.csv',     index=False)\n",
        "pd.DataFrame({'file_loc_test': test_all}).to_csv(csv_dir/'predict.csv', index=False)\n",
        "\n",
        "print(f\"Samples for CHG:     Train={len(tr_all)}  Val={len(val_all)}  Test={len(test_all)}\")\n",
        "print(f\"Samples for Energy:  Train={len(tr_en)}  Val={len(val_en)}  Test={len(set(test_all)&energy_dirs)}\")\n",
        "print(f\"Samples for DOS:     Train={len(tr_dos)}  Val={len(val_dos)}  Test={len(set(test_all)&dos_dirs)}\")"
      ]
    }
  ]
}