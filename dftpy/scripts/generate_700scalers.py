#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
generate_700scalers.py
--------------------------------------------------------------
1) è¯»å–è®­ç»ƒ CSVï¼ˆåˆ—å: filesï¼‰è·å¾—æ‰€æœ‰æ ·æœ¬æ–‡ä»¶å¤¹
2) å¯¹æ¯ä¸ªæ ·æœ¬çš„ POSCAR è®¡ç®— **700 ç»´æŒ‡çº¹**ï¼ˆnum_gamma=70ï¼‰
3) æŒ‰å…ƒç´  (C/H/N/O) ç´¯ç§¯ â†’ fit 4 ä¸ª MaxAbsScaler
4) ä¿å­˜ä¸º
      dftpy/scalers/Scale700_C.joblib
      dftpy/scalers/Scale700_H.joblib
      dftpy/scalers/Scale700_N.joblib
      dftpy/scalers/Scale700_O.joblib
--------------------------------------------------------------
"""

import os, sys, joblib, numpy as np
from pathlib import Path
from tqdm import tqdm
from sklearn.preprocessing import MaxAbsScaler

# â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ æ‰‹åŠ¨ä¿®æ”¹åŒº â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
train_list_csv = "/content/drive/MyDrive/DFT_CSVs/Train.csv"   # â† è®­ç»ƒ CSV
grid_spacing       = 0.7
cut_off_rad        = 5.0
widest_gaussian    = 6.0
narrowest_gaussian = 0.5
num_gamma          = 70        # â˜… 700 ç»´æŒ‡çº¹
padding_multiplier = 1.0
# â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

# ====== æŠŠé¡¹ç›®æ ¹ç›®å½•åŠ å…¥ sys.pathï¼ˆå‡è®¾è„šæœ¬ä½äº dftpy/scripts/ï¼‰ ====
repo_root = Path(__file__).resolve().parents[1]
sys.path.append(str(repo_root))

from dftpy.data_io import read_file_list, get_max_atom_count
from dftpy.fp       import fp_atom, pad_to

# ---------- Step-0  å‡†å¤‡ ----------
folders = read_file_list(train_list_csv, col="files")
if not folders:
    raise RuntimeError("è®­ç»ƒ CSV ä¸ºç©ºï¼Ÿ")

pad_size = int(get_max_atom_count(folders) * padding_multiplier)
print(f"[INFO] æ ·æœ¬æ•°={len(folders)}   padding_size={pad_size}")

buf = {e: [] for e in "CHNO"}         # æ”¶é›†å››ä¸ªå…ƒç´ çš„ 700-D å‘é‡

# ---------- Step-1  é€ç»“æ„è®¡ç®— 700-D æŒ‡çº¹ ----------
for fld in tqdm(folders, desc="fingerprint"):
    poscar = Path(fld) / "POSCAR"
    if not poscar.is_file():
        print("[SKIP] no POSCAR :", fld)
        continue

    fp700, _, _, _, _ = fp_atom(
        poscar,
        grid_spacing, cut_off_rad,
        widest_gaussian, narrowest_gaussian, num_gamma
    )                                   # (N_atoms, 700)

    # element split ------------------------------------------------------
    from pymatgen.io.vasp.inputs import Poscar
    struct = Poscar.from_file(poscar).structure
    elem_map = {6: "C", 1: "H", 7: "N", 8: "O"}

    for i, site in enumerate(struct):
        sym = elem_map.get(site.atomic_number)
        if not sym:          # ignore other elements
            continue
        vec = pad_to(fp700[i:i+1], pad_size)[0]   # (700,) after pad
        buf[sym].append(vec)

# ---------- Step-2  fit scaler & ä¿å­˜ ---------------------------
sc_dir = repo_root / "dftpy" / "scalers"
sc_dir.mkdir(exist_ok=True, parents=True)

for e in "CHNO":
    X = np.vstack(buf[e])                # (atoms, 700)
    if X.size == 0:
        print(f"[WARN] å…ƒç´  {e} åœ¨è®­ç»ƒé›†ç¼ºå¤±ï¼Œè·³è¿‡ scaler")
        continue
    scaler = MaxAbsScaler().fit(X)
    out = sc_dir / f"Scale700_{e}.joblib"
    joblib.dump(scaler, out)
    print(f"âœ” {out.name}  saved, X.shape={X.shape}")

print("\nğŸš€  All done.")
